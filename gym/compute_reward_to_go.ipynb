{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f077f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.83028155, 12.45292795, 12.05571363, 11.6375933 , 11.19746663,\n",
       "       10.7341754 , 10.24650042,  9.73315833,  9.19279825,  8.62399815,\n",
       "        8.02526122,  7.39501181,  6.73159137,  6.03325408,  5.29816219,\n",
       "        4.52438125,  3.709875  ,  2.8525    ,  1.95      ,  1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute reward_to_go \n",
    "# R_t := r_t + r_(t+1) * gamma^1 + r_(t+2) * gamma^2 +  ... + r_(T-1) * gamma^(T-1-t)\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "gamma = 0.95\n",
    "\n",
    "state, info = env.reset()\n",
    "terminated = False\n",
    "total_reward = 0.0\n",
    "\n",
    "states = []\n",
    "rewards = []\n",
    "actions = []\n",
    "next_states = []\n",
    "terminateds = []\n",
    "\n",
    "while not terminated:\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # record (s, a, r, s', terminated)\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    next_states.append(next_state)\n",
    "    terminateds.append(terminated)\n",
    "\n",
    "    # prepare next step\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "        \n",
    "reward_to_goes = []\n",
    "reward_to_go = 0.0\n",
    "T = len(states)\n",
    "for i in range(T-1, -1, -1): \n",
    "    reward = rewards[i]\n",
    "    reward_to_go = reward + reward_to_go * gamma\n",
    "    reward_to_goes.append(reward_to_go)\n",
    "reward_to_goes = np.array(reward_to_goes[::-1])\n",
    "reward_to_goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025a2788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.83028155, 12.45292795, 12.05571363, 11.6375933 , 11.19746663,\n",
       "       10.7341754 , 10.24650042,  9.73315833,  9.19279825,  8.62399815,\n",
       "        8.02526122,  7.39501181,  6.73159137,  6.03325408,  5.29816219,\n",
       "        4.52438125,  3.709875  ,  2.8525    ,  1.95      ,  1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same result as https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/ppo/core.py in discount_cumsum()\n",
    "import scipy\n",
    "\n",
    "reward_to_goes = scipy.signal.lfilter([1], [1, float(-gamma)], rewards[::-1], axis=0)[::-1]\n",
    "reward_to_goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe79d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
